Feuille de questions pour auto-évaluationTous les sujets abordés en cours, mini-projet, TP, ou encore les passages les plus importants des séminaires IBM pourront faire objet de question à l'examen écrit. Voici une liste (non exhaustive) de questions qui pourront néanmoins vous être utiles pour préparer l'épreuve.ModélisationUn entrepôt de données pour une entreprise de télécommunicationsBouygues télécom (fondée en 1994) est la troisième compagnie de télécommunications française, avec 10 millions d’utilisateurs, une part de marché de 20%, et 5.3 milliards d’euros de profits annuels.  En 2007, Bouyges a repensé son système d’aide à la decision. L’analyse des données des clients était un point central.Question 1 La compagnie souhait analyser des statistiques d’appel très détaillées.Une statistique d’appel doit contenir les informations suivantes.    L’émetteur (numéro ou identifiant de l'appelant)    Le destinataire (numéro ou identifiant de l'appelé)    La date et l'heure du début d'appel    La durée d'appel    Le type d'appel (Mobile, SMS, Fax, Fixe, ...)    Le compte facturé pour l’appel (attention : pas toujours l’émetteur)    Un identifiant unique pour chaque statistique d’appel    Un code correspondant au dysfonctionnement/erreur éventuellement produit pendant l’appelTravail demandé :    Proposer un schéma logique et physique pour l'entrepôt de données    Justifier la (semi,non)-additivité des mesures    Proposer 5 requêtes analytiques pertinentes    Estimer la taille de l'entrepôt sur 10 ansQuestion 2 - La compagnie souhaite mettre en place un système d’analyse des factures client.Une facture doit contenir les informations suivantes.    Le compte client (on considère que chaque client dispose d’un seul numéro)    La période de référence    Le coût (mensuel) des abonnements souscrits    Le coût total des communications effectuées (on ne considère que trois types de communications : mobile, livebox, et poste fixe)        Incluses dans le forfait        Hors forfait    Un identifiant unique pour chaque factureTravail demandé :    Proposer un schéma logique et physique pour l'entrepôt de données    Justifier la (semi,non)-additivité des mesures    Proposer 5 requêtes analytiques pertinentes    Estimer la taille de l'entrepôt sur 10 ansHierarchiesUn leader mondial dans la construction d’appareils photo souhaite faire évoluer sa propre offre de produits sur la base de données de la plateforme Flickr. Précisément, l’objectif est de concevoir un entrepôt de données permettant d’analyser l’utilisation des appareils par le bais des photos publiées sur Flickr. L'entrepôt doit permettre d'étudier les lieux ainsi que les périodes de l'année et les horaires de la journée où les appareils sont utilisés, mais aussi le lignage des appareils photos (par exemple, le modèle Nikon D3200 dérive du modèle Nikon D3100 qui dérive du D3000), et le créateur de chaque modèle (par exemple, le modèle Nikon D3200 à été conçu par Eiji Fumio).1) Proposez un schéma d’entrepôt de données permettant les analyses suivantes.    compter le nombre de photos réalisées pour chaque appareil photo ;    compter le nombre de photos prises par un appareil conçu par Eiji Fumio ;    pour tous les modèles dérivés du Nikon D3000, compter le nombre de photos réalisées par jour    indiquer les modèles historiquement les plus influents (on considère ici les appareils au sommets des hiérarchies de lignage).Questions ouvertes(réponse 10 lignes max)Quelle est la différence entre une base de données relationnelles et un entrepôt de données ? Pourquoi les bases de données relationnelles ne sont pas adaptées à la gestion des données massives ?Pourquoi a-t-on introduit les plateformes de Big-Data ? Quels sont les avantages et les inconvénients par rapport aux entrepôts de données ?Pourquoi est-il nécessaire d’optimiser l’évaluation des requêtes dans les bases de données relationnelles ? Illustrez l’intérêt de l’optimisation avec un exempleQuelle est la difference entre les approches schema-on-read et schema-on-write ?  Quelle est la difference entre les approches d'analyse descriptive et prédictive des données ? Quelles technologies sont associées à chaque type d'analyse ?Illustrer par des exemples les problématiques de volume, vélocité, et variété des données. Quelles solutions ont été proposées pour chaque problématique ?Quelles sont les mesures de complexité d'un programme map reduce ? Pourquoi la complexité en temps ne suffit pas ?Quel est l'espace de stockage réellement occupé par un fichier de 1TB stocké dans Hadoop ? Justifier.Quel composant hardware des serveurs a évolué beaucoup moins rapidement que les autres en terme de performances pour l'accès aux données ?Décrire un cas d'utilisation pour les entrepôts de données et un cas d'utilisation pour Hadoop.Quelle est la différence entre ETL et ELT ?Map/ReduceÀ l’aide du pseudo-code, écrire des fonctions map et reduce permettant de calculer les requêtes SQL suivantes. On supposera pour simplicité que R, S, et T soient des relations binaires. Pour simplicité on utilisera A et B pour indiquer la première et deuxième colonne de chaque relation. Important : pour un souci d'efficacité, il est demandé que les calculs ne soient pas réalisés par un seul et unique appel à la fonction reduce.1) SELECT COUNT(*) FROM R, S, T WHERE R.A = S.A AND R.A = T.A2) SELECT R.B FROM R, S, T WHERE R.A = S.A AND R.A = T.A WHERE T.B = 43) SELECT S.B FROM R, S, T WHERE R.A = S.A AND R.B = T.A 4) SELECT S.A, AVG(S.B) FROM S GROUP BY S.A5) SELECT COUNT(*) FROM R R1, R R2 WHERE R1.A = R2.B AND R1.B = R2.A6) SELECT R.A, S.A FROM R, S WHERE R.A < S.A7) SELECT DISTINCT R.A, S.A FROM R, S WHERE R.A < S.ASi les requêtes vous semblent trop abstraites, essayez d'abord de vous construire un jeu de données d'exemple ou de renommer les relations R, S, et T. Calculer le coût de communication associé à chaque requête (#octets transférés entre map et reduce). Vues Matérialisées1) Sur la base du schéma d'entrepôt de données que vous avez proposé pour Amazon (TD DW1), traduire les interrogations suivantes en requêtes SQL. Le nombre de produits par pays achetés après 22hLe nombre de produits achetés pour chaque heure de la journéeLe nombre de produits achetés après 22h par des clients ayant un compte Amazon premiumLe nombre de produits achetés après 21h par des clients français- Proposer deux (2) ensembles de vues matérialisés permettant d'optimiser ce (petit) workload. Pour cela, il faudra d'abord construire le treillis d'aggregation.2) Considérons le workload {Q1,Q2,Q3,Q4}.Calculer le treillis d'agrégation pour le workload.Proposer un ensemble de vues matérialisées permettant de répondre aux requêtes.Donner la réécriture des requêtes {Q1,Q2,Q3,Q4} sur l’ensemble des vues.Q1 :SELECT Magasin, Ville, avg(montant_vente)FROM VentesGROUP BY Magasin, VilleQ2 :SELECT Ville, Produit, Date, sum(montant_vente)FROM VentesGROUP BY Ville, Produit, DateQ3 :SELECT Ville, sum(montant_vente)WHERE Date BETWEEN ‘01/01/2017’ AND ‘01/01/2018’FROM VentesGROUP BY VilleQ4 :SELECT Date, max(montant_vente)FROM VentesGROUP BY DateOptimisationExpliquer le plan d'exécution suivant fourni par le SGBD Oracle.plan exec